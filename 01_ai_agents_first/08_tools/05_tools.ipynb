{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install openai-agents SDK"
      ],
      "metadata": {
        "id": "PdKwzEluDBN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents"
      ],
      "metadata": {
        "id": "3QdkOviEB2ay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f19056a-3bb5-4be4-9fe0-4c1c295552d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/100.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.4/100.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make your Jupyter Notebook capable of running asynchronous functions."
      ],
      "metadata": {
        "id": "7yD91lz4DIAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "7A5YLi3HCfBV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Google Gemini with OPENAI-Agent SDK"
      ],
      "metadata": {
        "id": "K3VTUWDaGFcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "gemini_api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "\n",
        "# Check if the API key is present; if not, raise an error\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=external_client,\n",
        "    tracing_disabled=True\n",
        ")"
      ],
      "metadata": {
        "id": "QSIWS6RvC-a4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, set_default_openai_client\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "gemini_api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "set_default_openai_client(external_client)"
      ],
      "metadata": {
        "id": "GsQmoaAAJ4JT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools\n",
        "The OpenAI Agents SDK provides a robust framework for integrating various tools into agents, enabling them to perform tasks such as data retrieval, web searches, and code execution. Here's an overview of the key points regarding tool integration:\n",
        "\n",
        "**Types of Tools:**\n",
        "\n",
        "1. **Hosted Tools:** These are pre-built tools running on OpenAI's servers, accessible via the [`OpenAIResponsesModel`]. Examples include:\n",
        "   - **WebSearchTool:** Enables agents to perform web searches.\n",
        "   - **FileSearchTool:** Allows retrieval of information from OpenAI Vector Stores.\n",
        "   - **ComputerTool:** Facilitates automation of computer-based tasks.\n",
        "\n",
        "2. **Function Calling:** This feature allows agents to utilize any Python function as a tool, enhancing their versatility.\n",
        "\n",
        "3. **Agents as Tools:** Agents can employ other agents as tools, enabling hierarchical task management without transferring control.\n",
        "\n",
        "**Implementing Tools:**\n",
        "\n",
        "- **Function Tools:** By decorating Python functions with `@function_tool`, they can be seamlessly integrated as tools for agents.\n",
        "\n",
        "**Tool Execution Flow:**\n",
        "\n",
        "- During an agent's operation, if a tool call is identified in the response, the SDK processes the tool call, appends the tool's response to the message history, and continues the loop until a final output is produced.\n",
        "\n",
        "**Error Handling:**\n",
        "\n",
        "- The SDK offers mechanisms to handle errors gracefully, allowing agents to recover from tool-related issues and continue their tasks effectively.\n",
        "\n",
        "For a comprehensive understanding and implementation details, refer to the [tools documentation](https://github.com/openai/openai-agents-python/blob/main/docs/tools.md)."
      ],
      "metadata": {
        "id": "FXBrF52IPBM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create tools"
      ],
      "metadata": {
        "id": "jLqBzJVcBQwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents.tool import function_tool"
      ],
      "metadata": {
        "id": "enCDgHfABsEO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool(\"get_weather\")\n",
        "def get_weather(location: str, unit: str = \"C\") -> str:\n",
        "  \"\"\"\n",
        "  Fetch the weather for a given location, returning a short description.\n",
        "  \"\"\"\n",
        "  # Example logic\n",
        "  return f\"The weather in {location} is 22 degrees {unit}.\""
      ],
      "metadata": {
        "id": "ULWmuAWsBSb8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool(\"piaic_student_finder\")\n",
        "def student_finder(student_roll: int) -> str:\n",
        "  \"\"\"\n",
        "  find the PIAIC student based on the roll number\n",
        "  \"\"\"\n",
        "  data = {1: \"Qasim\",\n",
        "          2: \"Sir Zia\",\n",
        "          3: \"Daniyal\"}\n",
        "\n",
        "  return data.get(student_roll, \"Not Found\")"
      ],
      "metadata": {
        "id": "6pP3qlQDB27P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect tools with Agent"
      ],
      "metadata": {
        "id": "sVs3-Q8HK_VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You only respond in haikus.\",\n",
        "        tools=[get_weather, student_finder], # add tools here\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(agent, \"Share PIAIC roll no1 student details.\")\n",
        "    print(result.final_output)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "id": "741wmWdpS22Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e1c61d-373f-47db-adcf-f43280db2c55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:openai.agents:[non-fatal] Tracing client error 401: {\n",
            "  \"error\": {\n",
            "    \"message\": \"Incorrect API key provided: AIzaSyBD***************************uG0U. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
            "    \"type\": \"invalid_request_error\",\n",
            "    \"param\": null,\n",
            "    \"code\": \"invalid_api_key\"\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qasim is the one,\n",
            "Roll number one, details found,\n",
            "A bright future waits.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tavily-python"
      ],
      "metadata": {
        "id": "AZUdzxti9JAQ",
        "outputId": "9d8df3d9-cb7d-4f48-89cf-158fc71666f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.7.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n",
            "Collecting tiktoken>=0.5.1 (from tavily-python)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2025.4.26)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (4.13.2)\n",
            "Downloading tavily_python-0.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, tavily-python\n",
            "Successfully installed tavily-python-0.7.1 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tavily import TavilyClient\n",
        "from google.colab import userdata\n",
        "\n",
        "tvly_API_KEY = userdata.get(\"tvly_API_KEY\")\n",
        "tavily_client = TavilyClient(api_key=tvly_API_KEY)\n"
      ],
      "metadata": {
        "id": "LJ3IlQAO9UoO"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool\n",
        "def search_tavily(query: str) -> str:\n",
        "  print(\"\\n\\n\\n I am in this function \\n\\n\\n\")\n",
        "  response = tavily_client.search(query)\n",
        "  return f\"{response}\""
      ],
      "metadata": {
        "id": "br0WeL3fBO6o"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import os\n",
        "from agents.tool import function_tool\n",
        "from agents import Agent, Runner, set_tracing_disabled\n",
        "from tavily import TavilyClient\n",
        "\n",
        "set_tracing_disabled(True)\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You can search online or simply answer the question.\",\n",
        "        tools=[search_tavily],\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(agent, \"What is usd exchange rate in pkr today.\")\n",
        "    print(result.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "id": "rlwSbUEl-RIA",
        "outputId": "84ac9c48-6203-42df-83c4-e9af2446771b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            " I am in this function \n",
            "\n",
            "\n",
            "\n",
            "The exchange rate between USD and PKR is approximately 281.90 PKR per 1 USD as of 19:00PM UTC today.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}